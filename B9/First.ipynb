{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests    \n",
    "response = requests.get('https://www.cbr-xml-daily.com/daily_json.js')    \n",
    "# print(response.text)\n",
    "currencies = response.json()\n",
    "\n",
    "# currencies['Valute']['CAD']  \n",
    "# currencies['Valute']['CZK']['Name']\n",
    "\n",
    "for i in currencies['Currency'].values():\n",
    "     if 'R01700J' in i['ID']:\n",
    "            print(i['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchange_rates(currency, format='full'):    \n",
    "    url = 'https://www.cbr-xml-daily.com/daily_json.js'  \n",
    "    response = requests.get(url).json()['Currency']    \n",
    "    data = response[currency]     \n",
    "    if format == 'full':    \n",
    "        return data      \n",
    "    elif format == 'value':    \n",
    "        return data['Value']    \n",
    "\n",
    "exchange_rates('CAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_name(ID):\n",
    "    url = 'https://www.cbr-xml-daily.com/daily_json.js'  \n",
    "    response = requests.get(url).json()['Currency']\n",
    "    for i in response.values():\n",
    "        if ID in i['ID']:\n",
    "            return i['Name']\n",
    "    \n",
    "currency_name('R01700J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup    \n",
    "import requests \n",
    "url = 'https://nplus1.com/news/2019/06/04/slothbot'   \n",
    "response = requests.get(url)  \n",
    "page = BeautifulSoup(response.text, 'html.parser')  \n",
    "page.title.text   \n",
    "page.find('time').text\n",
    "# print(page.find('div', class_='body').text)  \n",
    " \n",
    "# value = print(page.find('span', id='target').text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_header(url):\n",
    "     \n",
    "    response = requests.get(url)  \n",
    "    page = BeautifulSoup(response.text, 'html.parser')  \n",
    "    return page.find('h1').text\n",
    "\n",
    "wiki_header('https://en.wikipedia.org/wiki/Operating_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_programming_languages'  \n",
    "  \n",
    "response = requests.get(url)  \n",
    "page = BeautifulSoup(response.text, 'html.parser')  \n",
    "page.find('a')  \n",
    "\n",
    "links = page.find_all('a')  \n",
    " \n",
    "len(links)  \n",
    "# => 937\n",
    "  \n",
    "\n",
    "print([link.text for link in links[500:510]])  \n",
    "\n",
    "first_block = page.find('div', class_='div-col')  \n",
    "   \n",
    "links = first_block.find_all('a')  \n",
    "print([link.text for link in links[:10]])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actors(url):\n",
    "    response = requests.get(url)  \n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    first_block = page.find('div', id=\"actorList\")\n",
    "    names=first_block.find_all('li')\n",
    "    return print([actor.text for actor in names])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd  \n",
    "import requests \n",
    "url = 'https://www.cbr.com/key-indicators/'  \n",
    " \n",
    "pd.read_html(url)[3]   \n",
    "  \n",
    "# url = 'http://www.cbr.com'  \n",
    "# soup = BeautifulSoup(requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}).text, 'html.parser')  \n",
    "# # data = soup.find(class_='widget type_table name_metal opened').find(class_='content').find('table') \n",
    "# df = pd.read_html(str(data))[0]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.banks.com/banks/ratings/'\n",
    "soup = BeautifulSoup(requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}).text, 'html.parser') \n",
    "# data = soup.find('table', class_=\"standard-table standard-table--row-highlight margin-bottom-small margin-top-x-small\").find('tbody').text\n",
    "df = pd.read_html(url)[0] \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
